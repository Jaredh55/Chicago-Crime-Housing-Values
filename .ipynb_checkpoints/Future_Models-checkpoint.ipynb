{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Month Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to see how well simple regression models can predict the next months housing value. These models will include the current months price as a variable in addition to the crime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, anneal, Trials\n",
    "import hpsklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read modeling data\n",
    "model_df2 = pd.read_csv(\"model_data2.csv\")\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Column\n",
    "target_column = 'FUTURE MHV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split\n",
    "X = model_df2.loc[:,\"CRIMINAL DAMAGE ADJ\":\"MHV\"]\n",
    "y = model_df2[[target_column]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only changes to the Current_Models notebook is that we are predicting on \"FUTURE MHV\" and including the current \"MHV\" as a predictor. For these models we will not use the adjusted MHV as this value takes into consideration the average of all other community areas in Chicago. If this is to be of real world usefullness, you would not know what the average housing value of all other community areas would be in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "scaled_X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "scaled_X = pd.DataFrame(scaler.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first establish a baseline. The baseline will be using the current months housing value to predict the next months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9995375029474216\n",
      "Root Mean Squared Error: 1.9473158170946396\n"
     ]
    }
   ],
   "source": [
    "#Baseline RMSE and R-squared\n",
    "r2 = r2_score(model_df2[\"FUTURE MHV\"], model_df2[\"MHV\"])\n",
    "print(\"Mean Absolute Error: {}\".format(r2))\n",
    "rmse = np.sqrt(mean_squared_error(model_df2[\"FUTURE MHV\"], model_df2[\"MHV\"]))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a good baseline for RMSE and R^2. However, what we are perhaps more interested in from a business perspective is whether the price is going to go up or down. Just using the previous months price would provide no predictive power to the direction. Therefore, I will write a function below to measure how well models predict the directionality of the next months price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_df(y_test=y_test, y_pred=y_pred, data=model_df2):\n",
    "    results_df = y_test.copy()\n",
    "    results_df[\"Pred\"] = y_pred\n",
    "    results_df[\"MHV\"] = model_df2.loc[list(y_test.index),\"MHV\"]\n",
    "    results_df[\"pred hi low\"] = results_df.apply(lambda row: 1 if row[\"Pred\"] > row[\"MHV\"] else 0, axis=1)\n",
    "    results_df[\"real hi low\"] = results_df.apply(lambda row: 1 if row[\"FUTURE MHV\"] > row[\"MHV\"] else 0, axis=1)\n",
    "    results_df[\"correct\"] = results_df.apply(lambda row: 1 if row[\"pred hi low\"] == row[\"real hi low\"] else 0, axis=1)\n",
    "    results_df[\"real dif\"] = abs(results_df[\"FUTURE MHV\"] - results_df[\"MHV\"])\n",
    "    results_df[\"pred dif\"] = abs(results_df[\"Pred\"] - results_df[\"MHV\"])\n",
    "    results_df[\"ae\"] = abs(results_df[\"Pred\"] - results_df[\"FUTURE MHV\"])\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def percent_correct_directionality(results_df, min_dif=0):\n",
    "    return (results_df.loc[results_df[\"pred dif\"] > min_dif][\"correct\"].mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.53474676089517"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline directionality\n",
    "up_down = []\n",
    "for i, x in enumerate(list(X_test[\"MHV\"])):\n",
    "    if list(y_test[\"FUTURE MHV\"])[i] > x:\n",
    "        up_down.append(1)\n",
    "    else:\n",
    "        up_down.append(0)\n",
    "\n",
    "sum(up_down) / len(up_down) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick test of the future prices compared to the current prices show that the prices go up 54.5% of the time in the dataset. Therefore a model that predicted it to go up 100% of the time would be 54.5% accurate. This provides a good baseline for the ability of the model to predict the direction of price movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use hyperopt to tune parameters of random forest, I expect these parameters may be different than before since we are including a highly predictive column (the last months housing value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to minimize\n",
    "def rf_mse_cv(params, random_state=42, cv=3, X=scaled_X_train, y=y_train):\n",
    "    \n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_features': int(params['max_features'])} \n",
    "    model = RandomForestRegressor(criterion=\"mse\", random_state=42, **params)\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:57<00:00, 47.33s/it, best loss: 3.3381939722723346]\n",
      "CPU times: user 152 ms, sys: 199 ms, total: 351 ms\n",
      "Wall time: 6min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "space={'n_estimators': hp.uniform('n_estimators', 10, 1500),\n",
    "       'max_features' : hp.uniform('max_features', 2, 36)\n",
    "      }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=rf_mse_cv,\n",
    "          space=space, \n",
    "          algo=tpe.suggest,\n",
    "          max_evals=10,\n",
    "          trials=trials,\n",
    "          rstate=np.random.RandomState(42)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 25.82112911712644, 'n_estimators': 1433.6621996017927}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9996352833925544\n",
      "Root Mean Squared Error: 1.689352278356195\n",
      "Directionality %: 69.84687868080094\n"
     ]
    }
   ],
   "source": [
    "#Create RF model using best parameters and test\n",
    "rf = RandomForestRegressor(random_state=42,\n",
    "                           criterion=\"mse\",\n",
    "                           n_estimators=1433,\n",
    "                           max_features=25)\n",
    "\n",
    "rf_model = rf.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = rf_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(rf_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "rf_df = results_df(y_pred=y_pred)\n",
    "print(\"Directionality %: {}\".format(percent_correct_directionality(rf_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By all measures the random forest model does perform better than baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using hyperopt for GB regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to minimize\n",
    "def gb_mse_cv(params, random_state=42, cv=3, X=scaled_X_train, y=y_train):\n",
    "    \n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_features': int(params['max_features']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    model = GradientBoostingRegressor(loss='ls', random_state=42, **params)\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:20<00:00, 56.23s/it, best loss: 2.844469211607817]\n",
      "CPU times: user 159 ms, sys: 242 ms, total: 401 ms\n",
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "space={'n_estimators': hp.uniform('n_estimators', 10, 10000),\n",
    "       'max_features' : hp.uniform('max_features', 2, 36),\n",
    "       'learning_rate': hp.uniform('learning_rate', 0.01, 0.99)\n",
    "      }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=gb_mse_cv, \n",
    "          space=space, \n",
    "          algo=tpe.suggest,\n",
    "          max_evals=10,\n",
    "          trials=trials,\n",
    "          rstate=np.random.RandomState(42)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.11276197538164948,\n",
       " 'max_features': 33.23656573675881,\n",
       " 'n_estimators': 4453.876797888506}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9997370381029932\n",
      "Root Mean Squared Error: 1.4344613930280252\n",
      "Directionality %: 75.97173144876325\n"
     ]
    }
   ],
   "source": [
    "#Create GB model using best parameters and test\n",
    "gb = GradientBoostingRegressor(random_state=42, \n",
    "                               n_estimators=4453,\n",
    "                               max_features=33,\n",
    "                               learning_rate=0.11276197538164948)\n",
    "\n",
    "gb_model = gb.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = gb_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(gb_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "gb_df = results_df(y_pred=y_pred)\n",
    "print(\"Directionality %: {}\".format(percent_correct_directionality(gb_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9979442257170397\n",
      "Root Mean Squared Error: 4.0107922452317135\n",
      "Directionality %: 66.70592854338437\n"
     ]
    }
   ],
   "source": [
    "#KNN Regression\n",
    "knn = KNeighborsRegressor(n_neighbors = 1)\n",
    "\n",
    "knn_model = knn.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = knn_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(knn_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "knn_df = results_df(y_pred=y_pred)\n",
    "print(\"Directionality %: {}\".format(percent_correct_directionality(knn_df, min_dif=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.999600253445323\n",
      "Root Mean Squared Error: 1.7686211605906303\n",
      "Directionality %: 61.75893207695328\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = lr_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(lr_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "lr_df = results_df(y_pred=y_pred)\n",
    "print(\"Directionality %: {}\".format(percent_correct_directionality(lr_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9997059709212114\n",
      "Root Mean Squared Error: 1.516832389521937\n",
      "Directionality %: 78.955634079309\n"
     ]
    }
   ],
   "source": [
    "#Voting Regressor\n",
    "vr = VotingRegressor(estimators=[('rf', rf), ('knn', knn), ('gb', gb), ('lr', lr)])\n",
    "vr_model = vr.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = vr_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(vr_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "vr_df = results_df(y_pred=y_pred)\n",
    "print(\"Directionality %: {}\".format(percent_correct_directionality(vr_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9997268918677652\n",
      "Root Mean Squared Error: 1.4618734147538048\n",
      "Directionality %: 76.05025520219867\n"
     ]
    }
   ],
   "source": [
    "#Voting Regressor (w/o KNN)\n",
    "vr2 = VotingRegressor(estimators=[('rf', rf), ('gb', gb), ('lr', lr)])\n",
    "vr2_model = vr2.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = vr2_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(vr2_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "vr2_df = results_df(y_pred=y_pred)\n",
    "print(\"Directionality %: {}\".format(percent_correct_directionality(vr2_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting regressor with all models obtained the highest % Directionality, whereas the GB model scored the best RMSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Month Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to see how well the the current crime rates can predict the current housing price. In addition, I also intend to learn which types of crime have the greatest effect on housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, anneal, Trials\n",
    "import hpsklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read modeling data\n",
    "model_df2 = pd.read_csv(\"model_data2.csv\")\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting current housing value based on current crime rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Column\n",
    "target_column = 'MHV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split\n",
    "X = model_df2.loc[:,\"CRIMINAL DAMAGE ADJ\":\"DOMESTIC VIOLENCE ADJ\"]\n",
    "y = model_df2[[target_column]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Data\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "scaled_X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "scaled_X = pd.DataFrame(scaler.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using hyperopt to tune parameters of Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to minimize\n",
    "def rf_mse_cv(params, random_state=42, cv=3, X=scaled_X_train, y=y_train):\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_features': int(params['max_features'])} \n",
    "    model = RandomForestRegressor(criterion=\"mse\", random_state=42, **params)\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:34<00:00, 44.89s/it, best loss: 336.8892831497742]\n",
      "CPU times: user 140 ms, sys: 195 ms, total: 336 ms\n",
      "Wall time: 6min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Use Hyperopt fmin function to determine best parameters after 10 evals\n",
    "space={'n_estimators': hp.uniform('n_estimators', 10, 1500),\n",
    "       'max_features' : hp.uniform('max_features', 2, 30)\n",
    "      }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=rf_mse_cv,\n",
    "          space=space, \n",
    "          algo=tpe.suggest,\n",
    "          max_evals=10,\n",
    "          trials=trials,\n",
    "          rstate=np.random.RandomState(42)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 21.617400449398247, 'n_estimators': 1433.6621996017927}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9710608240953853\n",
      "Root Mean Squared Error: 15.019187291780348\n"
     ]
    }
   ],
   "source": [
    "#Create RF model using best parameters and test\n",
    "rf = RandomForestRegressor(random_state=42,\n",
    "                           criterion=\"mse\",\n",
    "                           n_estimators=int(best['n_estimators']),\n",
    "                           max_features=int(best['max_features']))\n",
    "\n",
    "rf_model = rf.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = rf_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(rf_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 feature  importance\n",
      "11        OFFENSE INVOLVING CHILDREN ADJ    0.254353\n",
      "9                 DECEPTIVE PRACTICE ADJ    0.115295\n",
      "8                              THEFT ADJ    0.091560\n",
      "7                  WEAPONS VIOLATION ADJ    0.089229\n",
      "23                          HOMICIDE ADJ    0.059157\n",
      "10                           ASSAULT ADJ    0.037735\n",
      "1                      OTHER OFFENSE ADJ    0.037482\n",
      "14                 CRIMINAL TRESPASS ADJ    0.030624\n",
      "4                MOTOR VEHICLE THEFT ADJ    0.029278\n",
      "3                            BATTERY ADJ    0.026109\n",
      "19                      PROSTITUTION ADJ    0.026072\n",
      "6                          NARCOTICS ADJ    0.025793\n",
      "26              LIQUOR LAW VIOLATION ADJ    0.023061\n",
      "0                    CRIMINAL DAMAGE ADJ    0.017871\n",
      "2                           BURGLARY ADJ    0.017142\n",
      "5                            ROBBERY ADJ    0.016430\n",
      "13  INTERFERENCE WITH PUBLIC OFFICER ADJ    0.014889\n",
      "12               CRIM SEXUAL ASSAULT ADJ    0.012904\n",
      "15            PUBLIC PEACE VIOLATION ADJ    0.011463\n",
      "16                       SEX OFFENSE ADJ    0.010267\n"
     ]
    }
   ],
   "source": [
    "#RF Feature Importances\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances[\"feature\"] = scaled_X_train.columns\n",
    "feature_importances[\"importance\"] = rf_model.feature_importances_\n",
    "print(feature_importances.sort_values(by='importance', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using hyperopt for Gradient Boosting Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to minimize\n",
    "def gb_mse_cv(params, random_state=42, cv=3, X=scaled_X_train, y=y_train):\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_features': int(params['max_features']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    model = GradientBoostingRegressor(loss='ls', random_state=42, **params)    \n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [09:22<00:00, 58.48s/it, best loss: 287.23414842785763]\n",
      "CPU times: user 153 ms, sys: 260 ms, total: 413 ms\n",
      "Wall time: 9min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Use Hyperopt fmin function to determine best parameters after 10 evals\n",
    "space={'n_estimators': hp.uniform('n_estimators', 10, 10000),\n",
    "       'max_features' : hp.uniform('max_features', 2, 35),\n",
    "       'learning_rate': hp.uniform('learning_rate', 0.01, 0.99)\n",
    "      }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=gb_mse_cv,\n",
    "          space=space, \n",
    "          algo=tpe.suggest,\n",
    "          max_evals=10,\n",
    "          trials=trials,\n",
    "          rstate=np.random.RandomState(42)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.11276197538164948,\n",
       " 'max_features': 32.31784321508944,\n",
       " 'n_estimators': 4453.876797888506}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9745518028036164\n",
      "Root Mean Squared Error: 14.084189635027736\n"
     ]
    }
   ],
   "source": [
    "#Create GB model using best parameters and test\n",
    "gb = GradientBoostingRegressor(random_state=42, \n",
    "                               n_estimators=int(best['n_estimators']),\n",
    "                               max_features=int(best['max_features']),\n",
    "                               learning_rate=best['learning_rate'])\n",
    "\n",
    "gb_model = gb.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = gb_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(gb_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature  importance\n",
      "11  OFFENSE INVOLVING CHILDREN ADJ    0.309454\n",
      "9           DECEPTIVE PRACTICE ADJ    0.128464\n",
      "8                        THEFT ADJ    0.096319\n",
      "7            WEAPONS VIOLATION ADJ    0.078450\n",
      "23                    HOMICIDE ADJ    0.048303\n",
      "1                OTHER OFFENSE ADJ    0.040451\n",
      "4          MOTOR VEHICLE THEFT ADJ    0.031124\n",
      "26        LIQUOR LAW VIOLATION ADJ    0.027115\n",
      "6                    NARCOTICS ADJ    0.024668\n",
      "19                PROSTITUTION ADJ    0.023001\n",
      "14           CRIMINAL TRESPASS ADJ    0.021965\n",
      "24                  KIDNAPPING ADJ    0.019566\n",
      "5                      ROBBERY ADJ    0.016544\n",
      "3                      BATTERY ADJ    0.016277\n",
      "10                     ASSAULT ADJ    0.013501\n",
      "17                INTIMIDATION ADJ    0.013062\n",
      "0              CRIMINAL DAMAGE ADJ    0.012359\n",
      "2                     BURGLARY ADJ    0.010873\n",
      "25                    GAMBLING ADJ    0.010572\n",
      "15      PUBLIC PEACE VIOLATION ADJ    0.010276\n"
     ]
    }
   ],
   "source": [
    "#GB Feature Importances\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances[\"feature\"] = scaled_X_train.columns\n",
    "feature_importances[\"importance\"] = gb_model.feature_importances_\n",
    "print(feature_importances.sort_values(by='importance', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let's see how a simple linear and KNN model perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9917673496306589\n",
      "Root Mean Squared Error: 8.010750197300672\n"
     ]
    }
   ],
   "source": [
    "#KNN Regression\n",
    "knn = KNeighborsRegressor(n_neighbors = 1)\n",
    "\n",
    "knn_model = knn.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = knn_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(knn_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.5900343827630077\n",
      "Root Mean Squared Error: 56.52975077525151\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = lr_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(lr_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather unsurprisingly, the out-of-the-box linear model does not perform well. However surprisingly the KNN model outperforms the RF and GB models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9884490804164828\n",
      "Root Mean Squared Error: 9.488807439652255\n"
     ]
    }
   ],
   "source": [
    "#Voting Regressor\n",
    "vr = VotingRegressor(estimators=[('rf', rf), ('knn', knn), ('gb',gb)])\n",
    "vr_model = vr.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = vr_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(vr_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again the simple KNN model appears to outperform even the ensemble voting model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let's see how the models perform on the the adjusted housing value (ie the difference in median housing value from the Chicago average). I have rerun the preprocessing steps this time setting \"MHV ADJ\" as the target. I will just borrow the tuned parameters from the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9740762172521555\n",
      "Root Mean Squared Error: 13.821385655337439\n"
     ]
    }
   ],
   "source": [
    "#RF model on adjusted housing value\n",
    "rf = RandomForestRegressor(random_state=42,\n",
    "                           criterion=\"mse\",\n",
    "                           n_estimators=1434,\n",
    "                           max_features=22)\n",
    "\n",
    "rf_model = rf.fit(scaled_X_train,y_train.values.ravel())\n",
    "y_pred = rf_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(rf_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9792239853808397\n",
      "Root Mean Squared Error: 12.373242358449236\n"
     ]
    }
   ],
   "source": [
    "#GB model on adjusted housing value\n",
    "gb = GradientBoostingRegressor(random_state=42, \n",
    "                               n_estimators=4454,\n",
    "                               max_features=32,\n",
    "                               learning_rate=0.11)\n",
    "\n",
    "gb_model = gb.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = gb_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(gb_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9922907639345195\n",
      "Root Mean Squared Error: 7.537165833858637\n"
     ]
    }
   ],
   "source": [
    "#KNN model on adjusted housing value\n",
    "knn = KNeighborsRegressor(n_neighbors = 1)\n",
    "\n",
    "knn_model = knn.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = knn_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(knn_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.6757859872121329\n",
      "Root Mean Squared Error: 48.87854722838262\n"
     ]
    }
   ],
   "source": [
    "#LR model on adjusted housing value\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = lr_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(lr_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9898990444978951\n",
      "Root Mean Squared Error: 8.627473371256347\n"
     ]
    }
   ],
   "source": [
    "#Voting Regressor\n",
    "vr = VotingRegressor(estimators=[('rf', rf), ('knn', knn), ('gb',gb)])\n",
    "vr_model = vr.fit(scaled_X_train, y_train.values.ravel())\n",
    "y_pred = vr_model.predict(scaled_X_test)\n",
    "\n",
    "print(\"R^2: {}\".format(vr_model.score(scaled_X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, each model appears to perform slightly better than it's non-adjusted counterpart, although not significantly. This indicates to me that broad effects such as the housing crisis and inflation play a role but perhaps not as significant of one as I expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
